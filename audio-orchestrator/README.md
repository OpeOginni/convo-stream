# ğŸµ Smart Audio Processing with Voice Activity Detection

A minimal real-time audio processing system using functional programming that **automatically** starts/stops transcription based on voice activity, saving AWS costs and providing intelligent speech detection.

## âœ¨ Features

- ğŸ¤ **Smart Voice Activity Detection (VAD)** - Auto-detects when you speak
- ğŸ“ **Auto transcription** - Starts only when speech is detected
- â±ï¸ **Auto-stop after 4s silence** - Saves AWS costs
- ğŸ”§ **Functional programming** - No classes, pure functions only
- ğŸ“Š **Real-time audio analysis** (volume, voice detection)
- ğŸ“ **Console logging only** - Clean, minimal interface
- ğŸ¯ **Zero manual control** - Just speak and it works!

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
bun install
```

### 2. Set Up AWS Credentials
Create a `.env` file:
```bash
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your-access-key-id
AWS_SECRET_ACCESS_KEY=your-secret-access-key
```

### 3. Start the Server
```bash
bun run start
```

### 4. Open Client
Open `client-example.html` in your browser and press F12 to see console logs!

## ğŸ¯ How It Works

### Smart Architecture
```
Browser â†’ Socket.IO â†’ Functional Server â†’ Voice Activity Detection
   â†“            â†“             â†“                     â†“
Console    Messages      Analysis              Smart Control
                                                â†™        â†˜
                                      Start AWS Transcribe  â† 4s Timer
```

### Intelligent Audio Flow
```
ğŸ™ï¸ You Speak â†’ ğŸµ Audio Analysis â†’ ğŸ§  Voice Detection â†’ ğŸ“ Auto-Start Transcription
                                                       â†˜
                                                4s Silence â†’ ğŸ”‡ Auto-Stop Transcription
```

## ğŸ“¡ Simple API

### Client â†’ Server
- `start-session` - Create session (auto-generated)
- `start-processing` - Start mic + transcription
- `stop-processing` - Stop everything

### Server â†’ Client
- `session-created` - Session ready
- `processing-started/stopped` - Status updates

## ğŸ¤ Audio Processing

### Functional Analysis
```typescript
const analyzeAudio = (frame: AudioFrame) => {
  // Calculate volume (RMS)
  const volume = calculateRMS(frame.samples);

  // Detect voice activity
  const isVoiceActive = volume > 5;

  return { volume, isVoiceActive };
};
```

### Real-Time Metrics
- **Volume**: 0-100% (Root Mean Square)
- **Voice Detection**: Boolean threshold
- **Sample Rate**: 16kHz optimized for speech
- **Buffer**: 1,024 samples (~64ms chunks)

## ğŸ“ AWS Transcribe Integration

### Pure Functions
```typescript
// Convert audio to PCM
const convertToPCM = (samples: Int16Array): Uint8Array => { ... }

// Create streaming iterator
const createAudioStream = (sessionId: string): AsyncIterable => { ... }

// Start transcription
const startTranscription = async (sessionId, userId, callbacks) => { ... }
```

### Features
- âœ… **Functional approach** - Pure functions, no side effects
- âœ… **Async iteration** - Streams audio to AWS
- âœ… **Error handling** - Graceful failure recovery
- âœ… **Session management** - Automatic cleanup

## ğŸ“Š Console Output

### Audio Analysis
```
ğŸ“Š Analysis: Volume 45% | Voice: DETECTED | ZCR: 0.123
ğŸ“Š Analysis: Volume 12% | Voice: Silent | ZCR: 0.089
```

### Smart Transcription Results
```
ğŸ™ï¸ TRANSCRIPT: "Hello" (0.85)
ğŸ™ï¸ TRANSCRIPT: "Hello, how are you today?" (0.92)
ğŸ™ï¸ TRANSCRIPT: "What can I help you with?" (0.89)
```

### Smart VAD Logs
```
ğŸ“ Created session session_user123_1234567890 for user user123 with smart VAD
â–¶ï¸  Started smart processing for session session_user123_1234567890 (VAD enabled)
ğŸ¤ Starting smart transcription for user123 (session_user123_1234567890)
ğŸ“Š Analysis: Volume 45% | Voice: DETECTED
ğŸ™ï¸ TRANSCRIPT: "Hello, how are you today?" (0.92)
ğŸ”‡ Stopping smart transcription for user123 (session_user123_1234567890) - silence timeout
```

## ğŸ® Smart Usage

1. **Open `client-example.html`** in browser
2. **Press F12** to open developer console
3. **Click "Create Session"** (auto-generates user ID)
4. **Click "Start Audio Processing"**
5. **Just speak normally** - transcription starts automatically!
6. **Stop speaking for 4 seconds** - transcription stops automatically
7. **Watch console logs** for intelligent analysis & transcription

### How Smart VAD Works:
- ğŸ¤ **Voice detected** â†’ Auto-starts transcription
- ğŸ”‡ **4s silence** â†’ Auto-stops transcription (saves AWS costs!)
- ğŸ“Š **Continuous monitoring** â†’ Real-time voice activity analysis
- ğŸ’¡ **Zero manual control** â†’ Just speak and it works!

## ğŸ”§ Technical Details

### Smart Voice Activity Detection (VAD)
```typescript
// Enhanced VAD with debouncing
const isVoiceActive = volume > 5;

// Smart transcription control with debouncing
if (isVoiceActive) {
  consecutiveVoiceFrames++;
  if (consecutiveVoiceFrames >= 3 && timeSinceLastStart > 2000) {
    startTranscription();  // Only after 3+ voice frames + 2s cooldown
  }
  resetSilenceTimer();
} else {
  consecutiveSilenceFrames++;
  if (consecutiveSilenceFrames >= 5) {
    startSilenceTimer();   // Auto-stop after sustained silence
  }
}
```

### Functional Programming
- âœ… **Pure functions** - No class instances
- âœ… **Global state** - Simple Maps for sessions + VAD state
- âœ… **Function composition** - Modular VAD + transcription logic
- âœ… **Callback pattern** - For async AWS operations

### Audio Processing
- **Web Audio API** - Browser-native audio
- **16kHz mono** - Optimized for speech transcription
- **Echo cancellation** - Clean audio input
- **Real-time chunks** - 64ms processing windows
- **Smart VAD** - Intelligent voice detection with debouncing

### VAD Improvements (Fixed Concurrent Streams Error)
- **Debouncing**: 3+ consecutive voice frames required to start transcription
- **Cooldown**: 2-second minimum between transcription starts
- **Silence Detection**: 5+ consecutive silence frames to trigger stop
- **State Tracking**: Consecutive frame counters prevent false triggers
- **Error Recovery**: Automatic state reset on transcription failures

### AWS Integration
- **PCM encoding** - AWS required format
- **Async iterables** - Streaming interface
- **Smart start/stop** - Only transcribe when speaking
- **Cost optimization** - Auto-stop saves AWS charges
- **Error recovery** - Automatic retry logic
- **Session cleanup** - Memory management

## ğŸš¨ Error Handling

### Microphone Issues
```javascript
// Browser console will show:
"âŒ Microphone access error: NotAllowedError"
```

### AWS Issues
```javascript
// Server console will show:
"âŒ AWS Transcribe error: Invalid credentials"
```

### Network Issues
```javascript
// Automatic reconnection via Socket.IO
"âŒ Disconnected from server"
"âœ… Connected to server"
```

## ğŸ¯ Smart Workflow

1. **Browser loads** â†’ Connects to Socket.IO server
2. **Create Session** â†’ Auto-generates session ID with VAD state
3. **Start Processing** â†’ Requests microphone access
4. **Smart Monitoring** â†’ Voice activity detection begins
5. **ğŸ¤ Speak** â†’ Auto-starts AWS transcription instantly
6. **ğŸ”‡ Silence 4s** â†’ Auto-stops transcription (cost savings!)
7. **Repeat** â†’ System continuously monitors and adapts
8. **Stop Processing** â†’ Clean shutdown with state cleanup

## ğŸ› ï¸ Troubleshooting

### No Audio
- Check microphone permissions in browser
- Verify Web Audio API support

### No Transcription
- Verify AWS credentials in `.env`
- Check AWS region settings
- Confirm IAM permissions for Transcribe

### Connection Issues
- Ensure server is running on port 3000
- Check firewall settings
- Verify Socket.IO connection

### Test Script
```bash
# Run the automated test script
node test-connection.js
```

The test script will:
- âœ… Connect to the server
- âœ… Create a test session
- âœ… Start/stop processing
- âœ… Send test audio data
- âœ… Verify all functionality works

### Specific Error Solutions

#### âŒ `LimitExceededException: You have reached your limit of concurrent streams, 25`
**Cause:** Voice Activity Detection was too sensitive, creating multiple transcription sessions rapidly
**Solution:**
- âœ… **Implemented debouncing**: Requires 3+ consecutive voice frames before starting transcription
- âœ… **Added cooldown**: 2-second minimum between transcription starts
- âœ… **Enhanced silence detection**: Requires 5+ consecutive silence frames before stopping
- âœ… **Better state management**: Prevents multiple concurrent sessions

#### âŒ `TypeError: undefined is not an object (evaluating 'data.sessionId')`
**Cause:** Session creation failed or client sent malformed data
**Solution:**
1. Check server console for session creation errors
2. Ensure client is connected before creating session
3. Verify client JavaScript console for errors
4. Run `node test-connection.js` to test basic connectivity

#### âŒ `Session not found`
**Cause:** Trying to start processing before session creation completes
**Solution:**
1. Always click "Create Session" first
2. Wait for "Session created" message in status
3. Then click "Start Audio Processing"
4. Check browser console for timing issues

## ğŸ“ Code Structure

```
ğŸ“ aws-transcribe/
  â””â”€â”€ index.ts          # Functional AWS Transcribe functions

ğŸ“„ index.ts             # Functional server (no classes)

ğŸ“„ client-example.html  # Simple console-based client

ğŸ“„ package.json         # Dependencies
```

---

**ğŸ‰ Simple, functional, and powerful!**

Your audio processing system now uses pure functional programming with AWS Transcribe for real-time speech recognition. Everything logs to the console - no UI complexity, just clean audio processing! ğŸš€
